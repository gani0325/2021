{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "211012_3.5-classifying-newswires.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gani0325/2021/blob/main/Deeplearning/211012_3_5_classifying_newswires_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "641Orjek6qmo"
      },
      "source": [
        "이 노트북은 케라스 창시자에게 배우는 딥러닝 책을 참고하였습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "808VW5hg6kkP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d40ab7dc-1887-44de-ef0f-f81f0068ef67"
      },
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il2hT6Gx6kkT"
      },
      "source": [
        "# 뉴스 기사 분류: 다중 분류 문제\n",
        "\n",
        "이 노트북은 [케라스 창시자에게 배우는 딥러닝](https://tensorflow.blog/%EC%BC%80%EB%9D%BC%EC%8A%A4-%EB%94%A5%EB%9F%AC%EB%8B%9D/) 책의 3장 5절의 코드 예제입니다. 책에는 더 많은 내용과 그림이 있습니다. 이 노트북에는 소스 코드에 관련된 설명만 포함합니다.\n",
        "\n",
        "----\n",
        "\n",
        "이전 섹션에서 완전 연결된 신경망을 사용해 벡터 입력을 어떻게 두 개의 클래스로 분류하는지 보았습니다. 두 개 이상의 클래스가 있을 때는 어떻게 해야 할까요?\n",
        "\n",
        "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류의 예입니다. 각 데이터 포인트가 정확히 하나의 범주로 분류되기 때문에 좀 더 정확히 말하면 단일 레이블 다중 분류 문제입니다. 각 데이터 포인트가 여러 개의 범주(가령, 토픽)에 속할 수 있다면 이런 문제는 다중 레이블 다중 분류의 문제가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sN1Sh5E6kkV"
      },
      "source": [
        "## 로이터 데이터셋\n",
        "\n",
        "1986년에 로이터에서 공개한 짧은 뉴스 기사와 토픽의 집합인 로이터 데이터셋을 사용하겠습니다. 이 데이터셋은 텍스트 분류를 위해 널리 사용되는 간단한 데이터셋입니다. 46개의 토픽이 있으며 어떤 토픽은 다른 것에 비해 데이터가 많습니다. 각 토픽은 훈련 세트에 최소한 10개의 샘플을 가지고 있습니다.\n",
        "\n",
        "IMDB와 MNIST와 마찬가지로 로이터 데이터셋은 케라스에 포함되어 있습니다. 한 번 살펴보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryM6tBwo6kkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95ce0b9-4247-4b63-d31c-846e8f2cdfef"
      },
      "source": [
        "from keras.datasets import reuters\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Tw4z9d6kkW"
      },
      "source": [
        "IMDB 데이터셋에서처럼 num_words=10000 매개변수는 데이터에서 가장 자주 등장하는 단어 10,000개로 제한합니다.\n",
        "\n",
        "여기에는 8,982개의 훈련 샘플과 2,246개의 테스트 샘플이 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wG7uLkiI6kkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72104ff0-6497-477f-cdfe-13091918a897"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8982"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143digLJ6kkX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f0bc74-113b-4ca9-83f1-e06d75c08a4f"
      },
      "source": [
        "len(test_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2246"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHr1EZBw6kkY"
      },
      "source": [
        "IMDB 리뷰처럼 각 샘플은 정수 리스트입니다(단어 인덱스):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l6VLo8o6kkY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20370b69-6f2d-4915-b890-b011b5a99eb8"
      },
      "source": [
        "train_data[10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 245,\n",
              " 273,\n",
              " 207,\n",
              " 156,\n",
              " 53,\n",
              " 74,\n",
              " 160,\n",
              " 26,\n",
              " 14,\n",
              " 46,\n",
              " 296,\n",
              " 26,\n",
              " 39,\n",
              " 74,\n",
              " 2979,\n",
              " 3554,\n",
              " 14,\n",
              " 46,\n",
              " 4689,\n",
              " 4329,\n",
              " 86,\n",
              " 61,\n",
              " 3499,\n",
              " 4795,\n",
              " 14,\n",
              " 61,\n",
              " 451,\n",
              " 4329,\n",
              " 17,\n",
              " 12]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-tFN0fx6kkZ"
      },
      "source": [
        "궁금한 경우를 위해 어떻게 단어로 디코딩하는지 알아보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8Z-pvla6kka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea86f6d-ce1d-4825-e94c-023a14edb107"
      },
      "source": [
        "word_index = reuters.get_word_index()\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "# 0, 1, 2는 '패딩', '문서 시작', '사전에 없음'을 위한 인덱스이므로 3을 뺍니다\n",
        "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
            "557056/550378 [==============================] - 0s 0us/step\n",
            "565248/550378 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0t_ZdAR6kka",
        "outputId": "142fc0a9-4de5-444e-9f51-c27bd0af24ed"
      },
      "source": [
        "decoded_newswire"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uvm5ih7p6kka"
      },
      "source": [
        "샘플에 연결된 레이블은 토픽의 인덱스로 0과 45 사이의 정수입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj3DG_Q_6kkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f0854f-489a-412f-cca9-5fff7725f75a"
      },
      "source": [
        "train_labels[10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyS4YPKb6kkb"
      },
      "source": [
        "## 데이터 준비\n",
        "\n",
        "이전의 예제와 동일한 코드를 사용해서 데이터를 벡터로 변환합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9luh77BS6kkb"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 데이터 벡터 변환\n",
        "x_train = vectorize_sequences(train_data)\n",
        "# 테스트 데이터 벡터 변환\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7c2EDpac6kkc"
      },
      "source": [
        "레이블을 벡터로 바꾸는 방법은 두 가지입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩이라고도 부릅니다. 원-핫 인코딩에 대한 자세한 설명은 6.1절을 참고하세요. 이 경우 레이블의 원-핫 인코딩은 각 레이블의 인덱스 자리는 1이고 나머지는 모두 0인 벡터입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yE8UFDJ6kkc"
      },
      "source": [
        "def to_one_hot(labels, dimension=46):\n",
        "    results = np.zeros((len(labels), dimension))\n",
        "    for i, label in enumerate(labels):\n",
        "        results[i, label] = 1.\n",
        "    return results\n",
        "\n",
        "# 훈련 레이블 벡터 변환\n",
        "one_hot_train_labels = to_one_hot(train_labels)\n",
        "# 테스트 레이블 벡터 변환\n",
        "one_hot_test_labels = to_one_hot(test_labels)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je1A_aOp6kkc"
      },
      "source": [
        "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_G7rgVc6kkc"
      },
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "one_hot_train_labels = to_categorical(train_labels)\n",
        "one_hot_test_labels = to_categorical(test_labels)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgCgmH7c6kkd"
      },
      "source": [
        "## 모델 구성\n",
        "\n",
        "이 토픽 분류 문제는 이전의 영화 리뷰 분류 문제와 비슷해 보입니다. 두 경우 모두 짧은 텍스트를 분류하는 것이죠. 여기에서는 새로운 제약 사항이 추가되었습니다. 출력 클래스의 개수가 2에서 46개로 늘어난 점입니다. 출력 공간의 차원이 훨씬 커졌습니다.\n",
        "\n",
        "이전에 사용했던 것처럼 `Dense` 층을 쌓으면 각 층은 이전 층의 출력에서 제공한 정보만 사용할 수 있습니다. 한 층이 분류 문제에 필요한 일부 정보를 누락하면 그 다음 층에서 이를 복원할 방법이 없습니다. 각 층은 잠재적으로 정보의 병목이 될 수 있습니다. 이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 46개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목 지점처럼 동작할 수 있습니다.\n",
        "\n",
        "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TahofHT56kkd"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObrUWCS86kkf"
      },
      "source": [
        "이 구조에서 주목해야 할 점이 두 가지 있습니다:\n",
        "\n",
        "* 마지막 `Dense` 층의 크기가 46입니다. 각 입력 샘플에 대해서 46차원의 벡터를 출력한다는 뜻입니다. 이 벡터의 각 원소(각 차원)은 각기 다른 출력 클래스가 인코딩된 것입니다.\n",
        "* 마지막 층에 `softmax` 활성화 함수가 사용되었습니다. MNIST 예제에서 이런 방식을 보았습니다. 각 입력 샘플마다 46개의 출력 클래스에 대한 확률 분포를 출력합니다. 즉, 46차원의 출력 벡터를 만들며 `output[i]`는 어떤 샘플이 클래스 `i`에 속할 확률입니다. 46개의 값을 모두 더하면 1이 됩니다.\n",
        "\n",
        "이런 문제에 사용할 최선의 손실 함수는 `categorical_crossentropy`입니다. 이 함수는 두 확률 분포의 사이의 거리를 측정합니다. 여기에서는 네트워크가 출력한 확률 분포와 진짜 레이블의 분포 사이의 거리입니다. 두 분포 사이의 거리를 최소화하면 진짜 레이블에 가능한 가까운 출력을 내도록 모델을 훈련하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSSglkiA6kkf"
      },
      "source": [
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssrW5YYN6kkf"
      },
      "source": [
        "## 훈련 검증\n",
        "\n",
        "훈련 데이터에서 1,000개의 샘플을 따로 떼어서 검증 세트로 사용하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcJ8UT-Y6kkg"
      },
      "source": [
        "x_val = x_train[:1000]\n",
        "partial_x_train = x_train[1000:]\n",
        "\n",
        "y_val = one_hot_train_labels[:1000]\n",
        "partial_y_train = one_hot_train_labels[1000:]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB5SeYB16kkg"
      },
      "source": [
        "이제 20번의 에포크로 모델을 훈련시킵니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "RhOdCeOu6kkg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9382320c-0254-4f0f-9d99-fa5d6abd4894"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 2s 65ms/step - loss: 2.5849 - accuracy: 0.5346 - val_loss: 1.7073 - val_accuracy: 0.6320\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 1.3989 - accuracy: 0.7047 - val_loss: 1.2845 - val_accuracy: 0.7220\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 1s 51ms/step - loss: 1.0319 - accuracy: 0.7791 - val_loss: 1.0987 - val_accuracy: 0.7640\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.8130 - accuracy: 0.8289 - val_loss: 1.0142 - val_accuracy: 0.7800\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.6482 - accuracy: 0.8658 - val_loss: 0.9809 - val_accuracy: 0.7900\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.5225 - accuracy: 0.8924 - val_loss: 0.9101 - val_accuracy: 0.8020\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 1s 63ms/step - loss: 0.4233 - accuracy: 0.9122 - val_loss: 0.9016 - val_accuracy: 0.8040\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.3428 - accuracy: 0.9301 - val_loss: 0.8754 - val_accuracy: 0.8060\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.2824 - accuracy: 0.9386 - val_loss: 0.8832 - val_accuracy: 0.8200\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.2416 - accuracy: 0.9441 - val_loss: 0.9004 - val_accuracy: 0.8210\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.2091 - accuracy: 0.9469 - val_loss: 0.9125 - val_accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.1857 - accuracy: 0.9534 - val_loss: 0.9398 - val_accuracy: 0.8050\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.1655 - accuracy: 0.9530 - val_loss: 0.9502 - val_accuracy: 0.8020\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.1511 - accuracy: 0.9548 - val_loss: 0.9335 - val_accuracy: 0.8170\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.1407 - accuracy: 0.9572 - val_loss: 1.0103 - val_accuracy: 0.7960\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.1343 - accuracy: 0.9550 - val_loss: 0.9667 - val_accuracy: 0.8120\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 1s 61ms/step - loss: 0.1241 - accuracy: 0.9577 - val_loss: 1.0262 - val_accuracy: 0.7930\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.1199 - accuracy: 0.9575 - val_loss: 1.0546 - val_accuracy: 0.7980\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 1s 56ms/step - loss: 0.1174 - accuracy: 0.9577 - val_loss: 1.0530 - val_accuracy: 0.8060\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.1144 - accuracy: 0.9577 - val_loss: 1.0463 - val_accuracy: 0.8070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrmNjOSD6kkg"
      },
      "source": [
        "손실과 정확도 곡선을 그려 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qGqOnOr6kkg"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7i456Mb6kkg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "709a3331-849d-430e-f36e-90447cd500c3"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0grXiY0n6kkh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ad8a7dad-5ee8-4406-e734-8ec711bf1726"
      },
      "source": [
        "plt.clf()   # 그래프를 초기화합니다\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbyghvMT6kkh"
      },
      "source": [
        "이 모델은 9번째 에포크 이후에 과대적합이 시작됩니다. 9번의 에포크로 새로운 모델을 훈련하고 테스트 세트에서 평가하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo-t-T1_6kkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986e2e81-e3b3-4ba3-d9ce-160b1603a73c"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=9,\n",
        "          batch_size=512,\n",
        "          validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, one_hot_test_labels)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "16/16 [==============================] - 2s 67ms/step - loss: 2.5654 - accuracy: 0.5286 - val_loss: 1.6926 - val_accuracy: 0.6480\n",
            "Epoch 2/9\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 1.4218 - accuracy: 0.6972 - val_loss: 1.3501 - val_accuracy: 0.6950\n",
            "Epoch 3/9\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 1.0961 - accuracy: 0.7580 - val_loss: 1.1742 - val_accuracy: 0.7410\n",
            "Epoch 4/9\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.8821 - accuracy: 0.8096 - val_loss: 1.0739 - val_accuracy: 0.7510\n",
            "Epoch 5/9\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.7132 - accuracy: 0.8469 - val_loss: 0.9853 - val_accuracy: 0.7940\n",
            "Epoch 6/9\n",
            "16/16 [==============================] - 1s 62ms/step - loss: 0.5724 - accuracy: 0.8771 - val_loss: 0.9363 - val_accuracy: 0.8110\n",
            "Epoch 7/9\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.4653 - accuracy: 0.9009 - val_loss: 0.9021 - val_accuracy: 0.8090\n",
            "Epoch 8/9\n",
            "16/16 [==============================] - 1s 60ms/step - loss: 0.3765 - accuracy: 0.9207 - val_loss: 0.8872 - val_accuracy: 0.8160\n",
            "Epoch 9/9\n",
            "16/16 [==============================] - 1s 59ms/step - loss: 0.3112 - accuracy: 0.9337 - val_loss: 0.9001 - val_accuracy: 0.8120\n",
            "71/71 [==============================] - 0s 4ms/step - loss: 0.9907 - accuracy: 0.7867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bL4VpaG6kkh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "750cd096-b474-453b-d6f8-937456801942"
      },
      "source": [
        "results"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9907399415969849, 0.7867319583892822]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbNpl6Xu6kki"
      },
      "source": [
        "대략 78%의 정확도를 달성했습니다. 균형 잡힌 이진 분류 문제에서 완전히 무작위로 분류하면 50%의 정확도를 달성합니다. 이 문제는 불균형한 데이터셋을 사용하므로 무작위로 분류하면 19% 정도를 달성합니다. 여기에 비하면 이 결과는 꽤 좋은 편입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_XJgAOL6kki",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c512d56c-d758-45e0-8e8b-204b2b609df1"
      },
      "source": [
        "import copy\n",
        "\n",
        "test_labels_copy = copy.copy(test_labels)\n",
        "np.random.shuffle(test_labels_copy)\n",
        "float(np.sum(np.array(test_labels) == np.array(test_labels_copy))) / len(test_labels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.17275155832591274"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcMfCMNV6kki"
      },
      "source": [
        "## 새로운 데이터에 대해 예측하기\n",
        "\n",
        "모델 인스턴스의 `predict` 메서드는 46개 토픽에 대한 확률 분포를 반환합니다. 테스트 데이터 전체에 대한 토픽을 예측해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgSVOkZ16kki"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2Czt0O86kki"
      },
      "source": [
        "`predictions`의 각 항목은 길이가 46인 벡터입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvfGdmnf6kkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38b594d-0895-46c1-d1cf-debf857c6382"
      },
      "source": [
        "predictions[0].shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(46,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TabmZFVg6kkj"
      },
      "source": [
        "이 벡터의 원소 합은 1입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvR4G4Cl6kkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b56ba92-497e-4fc1-e5bb-b0fee937de49"
      },
      "source": [
        "np.sum(predictions[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0000001"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF2Kd8G36kkj"
      },
      "source": [
        "가장 큰 값이 예측 클래스가 됩니다. 즉, 가장 확률이 높은 클래스입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AV3JWlZy6kkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0259f517-c2b6-4f33-c402-7479e6c9276a"
      },
      "source": [
        "np.argmax(predictions[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a8mTWuo6kkj"
      },
      "source": [
        "## 레이블과 손실을 다루는 다른 방법\n",
        "\n",
        "앞서 언급한 것처럼 레이블을 인코딩하는 다른 방법은 다음과 같이 정수 텐서로 변환하는 것입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OXolfjb6kkj"
      },
      "source": [
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwhCnWDW6kkk"
      },
      "source": [
        "이 방식을 사용하려면 손실 함수 하나만 바꾸면 됩니다. 코드 3-21에 사용된 손실 함수 `categorical_crossentropy`는 레이블이 범주형 인코딩되어 있을 것이라고 기대합니다. 정수 레이블을 사용할 때는 `sparse_categorical_crossentropy`를 사용해야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qcAgz476kkk"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbMRzXDc6kkk"
      },
      "source": [
        "이 손실 함수는 인터페이스만 다를 뿐이고 수학적으로는 `categorical_crossentropy`와 동일합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BmShDPx6kkk"
      },
      "source": [
        "## 충분히 큰 중간층을 두어야 하는 이유\n",
        "\n",
        "앞서 언급한 것처럼 마지막 출력이 46차원이기 때문에 중간층의 히든 유닛이 46개보다 많이 적어서는 안 됩니다. 46차원보다 훨씬 작은 중간층(예를 들면 4차원)을 두면 정보의 병목이 어떻게 나타나는지 확인해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRzZuzGn6kkk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbe86ceb-6250-48c9-e776-c745f2014bb7"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(4, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 22ms/step - loss: 3.1735 - accuracy: 0.1888 - val_loss: 2.5141 - val_accuracy: 0.3970\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 2.0435 - accuracy: 0.4440 - val_loss: 1.7538 - val_accuracy: 0.5870\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 1.4220 - accuracy: 0.6239 - val_loss: 1.4410 - val_accuracy: 0.6220\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 1.1876 - accuracy: 0.6754 - val_loss: 1.3951 - val_accuracy: 0.6540\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 1.0517 - accuracy: 0.7338 - val_loss: 1.3450 - val_accuracy: 0.6810\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.9410 - accuracy: 0.7650 - val_loss: 1.3622 - val_accuracy: 0.6980\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.8508 - accuracy: 0.7876 - val_loss: 1.3634 - val_accuracy: 0.6920\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.7764 - accuracy: 0.8022 - val_loss: 1.3653 - val_accuracy: 0.7090\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.7159 - accuracy: 0.8122 - val_loss: 1.3908 - val_accuracy: 0.7070\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.6662 - accuracy: 0.8232 - val_loss: 1.4256 - val_accuracy: 0.7080\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.6215 - accuracy: 0.8344 - val_loss: 1.4723 - val_accuracy: 0.7030\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5844 - accuracy: 0.8401 - val_loss: 1.5271 - val_accuracy: 0.7060\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5556 - accuracy: 0.8420 - val_loss: 1.5789 - val_accuracy: 0.7030\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.5261 - accuracy: 0.8499 - val_loss: 1.6233 - val_accuracy: 0.6960\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.5026 - accuracy: 0.8552 - val_loss: 1.6850 - val_accuracy: 0.6860\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.4775 - accuracy: 0.8646 - val_loss: 1.7793 - val_accuracy: 0.6970\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.4586 - accuracy: 0.8707 - val_loss: 1.8048 - val_accuracy: 0.7060\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.4405 - accuracy: 0.8751 - val_loss: 1.8732 - val_accuracy: 0.7050\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.4271 - accuracy: 0.8802 - val_loss: 1.9194 - val_accuracy: 0.7020\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.4114 - accuracy: 0.8860 - val_loss: 2.0220 - val_accuracy: 0.6880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff183bf6590>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33BxNZRc6kkk"
      },
      "source": [
        "검증 정확도의 최고 값은 약 71%로 8% 정도 감소되었습니다. 이런 손실의 대부분 원인은 많은 정보(46개 클래스의 분할 초평면을 복원하기에 충분한 정보)를 중간층의 저차원 표현 공간으로 압축하려고 했기 때문입니다. 이 네트워크는 필요한 정보 대부분을 4차원 표현 안에 구겨 넣었지만 전부는 넣지 못했습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHi1312Q6kkk"
      },
      "source": [
        "## 추가 실험\n",
        "\n",
        "* 더 크거나 작은 층을 사용해 보세요: 32개 유닛, 128개 유닛 등\n",
        "* 여기에서 두 개의 은닉층을 사용했습니다. 한 개의 은닉층이나 세 개의 은닉층을 사용해 보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbR7jEWC8jtV",
        "outputId": "fe4d5e74-bfd9-4df4-f13e-1ee5db7019a4"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 2.1606 - accuracy: 0.5685 - val_loss: 1.3283 - val_accuracy: 0.7070\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 1.0787 - accuracy: 0.7672 - val_loss: 1.0594 - val_accuracy: 0.7740\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.7611 - accuracy: 0.8348 - val_loss: 0.9497 - val_accuracy: 0.8060\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.5503 - accuracy: 0.8841 - val_loss: 0.9047 - val_accuracy: 0.8070\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 1s 23ms/step - loss: 0.4092 - accuracy: 0.9136 - val_loss: 0.9102 - val_accuracy: 0.8040\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.3150 - accuracy: 0.9300 - val_loss: 0.9121 - val_accuracy: 0.8140\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 1s 21ms/step - loss: 0.2479 - accuracy: 0.9437 - val_loss: 0.9060 - val_accuracy: 0.8220\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 1s 20ms/step - loss: 0.2126 - accuracy: 0.9485 - val_loss: 0.9587 - val_accuracy: 0.8130\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1840 - accuracy: 0.9499 - val_loss: 0.9663 - val_accuracy: 0.8160\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1647 - accuracy: 0.9529 - val_loss: 0.9711 - val_accuracy: 0.8250\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1534 - accuracy: 0.9563 - val_loss: 1.0609 - val_accuracy: 0.8030\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 1s 22ms/step - loss: 0.1423 - accuracy: 0.9573 - val_loss: 1.1281 - val_accuracy: 0.8010\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 2s 25ms/step - loss: 0.1368 - accuracy: 0.9555 - val_loss: 1.1116 - val_accuracy: 0.8010\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1329 - accuracy: 0.9579 - val_loss: 1.1200 - val_accuracy: 0.8030\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1249 - accuracy: 0.9560 - val_loss: 1.1525 - val_accuracy: 0.7990\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 2s 26ms/step - loss: 0.1226 - accuracy: 0.9578 - val_loss: 1.1956 - val_accuracy: 0.7990\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 0.1186 - accuracy: 0.9575 - val_loss: 1.2537 - val_accuracy: 0.7950\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 2s 39ms/step - loss: 0.1169 - accuracy: 0.9570 - val_loss: 1.2817 - val_accuracy: 0.7890\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1174 - accuracy: 0.9569 - val_loss: 1.3200 - val_accuracy: 0.7910\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 2s 24ms/step - loss: 0.1101 - accuracy: 0.9589 - val_loss: 1.2304 - val_accuracy: 0.8060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff1830e1b10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo6DiJIM9Lnh",
        "outputId": "822d2332-127d-4dfe-93fb-02c2e2e645b2"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(46, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(partial_x_train,\n",
        "          partial_y_train,\n",
        "          epochs=20,\n",
        "          batch_size=128,\n",
        "          validation_data=(x_val, y_val))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "63/63 [==============================] - 4s 42ms/step - loss: 2.0001 - accuracy: 0.5788 - val_loss: 1.3453 - val_accuracy: 0.6890\n",
            "Epoch 2/20\n",
            "63/63 [==============================] - 2s 28ms/step - loss: 1.0875 - accuracy: 0.7562 - val_loss: 1.0947 - val_accuracy: 0.7530\n",
            "Epoch 3/20\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.7622 - accuracy: 0.8235 - val_loss: 1.0860 - val_accuracy: 0.7420\n",
            "Epoch 4/20\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.5532 - accuracy: 0.8657 - val_loss: 1.0163 - val_accuracy: 0.7840\n",
            "Epoch 5/20\n",
            "63/63 [==============================] - 2s 35ms/step - loss: 0.4060 - accuracy: 0.9068 - val_loss: 1.0475 - val_accuracy: 0.7820\n",
            "Epoch 6/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.3069 - accuracy: 0.9302 - val_loss: 1.0358 - val_accuracy: 0.7860\n",
            "Epoch 7/20\n",
            "63/63 [==============================] - 2s 30ms/step - loss: 0.2462 - accuracy: 0.9446 - val_loss: 1.0106 - val_accuracy: 0.8080\n",
            "Epoch 8/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.2070 - accuracy: 0.9499 - val_loss: 1.2168 - val_accuracy: 0.7680\n",
            "Epoch 9/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1841 - accuracy: 0.9530 - val_loss: 1.2870 - val_accuracy: 0.7690\n",
            "Epoch 10/20\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1681 - accuracy: 0.9525 - val_loss: 1.1341 - val_accuracy: 0.7870\n",
            "Epoch 11/20\n",
            "63/63 [==============================] - 2s 32ms/step - loss: 0.1563 - accuracy: 0.9567 - val_loss: 1.2500 - val_accuracy: 0.7790\n",
            "Epoch 12/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1457 - accuracy: 0.9570 - val_loss: 1.3056 - val_accuracy: 0.7690\n",
            "Epoch 13/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1425 - accuracy: 0.9558 - val_loss: 1.2275 - val_accuracy: 0.7860\n",
            "Epoch 14/20\n",
            "63/63 [==============================] - 2s 36ms/step - loss: 0.1351 - accuracy: 0.9562 - val_loss: 1.3196 - val_accuracy: 0.7880\n",
            "Epoch 15/20\n",
            "63/63 [==============================] - 2s 38ms/step - loss: 0.1292 - accuracy: 0.9564 - val_loss: 1.4311 - val_accuracy: 0.7730\n",
            "Epoch 16/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1234 - accuracy: 0.9553 - val_loss: 1.4267 - val_accuracy: 0.7850\n",
            "Epoch 17/20\n",
            "63/63 [==============================] - 2s 31ms/step - loss: 0.1186 - accuracy: 0.9582 - val_loss: 1.3839 - val_accuracy: 0.7820\n",
            "Epoch 18/20\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.1167 - accuracy: 0.9565 - val_loss: 1.3023 - val_accuracy: 0.7850\n",
            "Epoch 19/20\n",
            "63/63 [==============================] - 2s 34ms/step - loss: 0.1116 - accuracy: 0.9551 - val_loss: 1.4152 - val_accuracy: 0.7770\n",
            "Epoch 20/20\n",
            "63/63 [==============================] - 2s 33ms/step - loss: 0.1059 - accuracy: 0.9570 - val_loss: 1.5338 - val_accuracy: 0.7760\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff183fa0610>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPRc44o_6kkl"
      },
      "source": [
        "## 정리\n",
        "\n",
        "다음은 이 예제에서 배운 것들입니다.\n",
        "\n",
        "* N개의 클래스로 데이터 포인트를 분류하려면 네트워크의 마지막 `Dense` 층의 크기는 N이어야 합니다.\n",
        "* 단일 레이블, 다중 분류 문제에서는 N개의 클래스에 대한 확률 분포를 출력하기 위해 `softmax` 활성화 함수를 사용해야 합니다.\n",
        "* 이런 문제에는 항상 범주형 크로스엔트로피를 사용해야 합니다. 이 함수는 모델이 출력한 확률 분포와 타깃 분포 사이의 거리를 최소화합니다.\n",
        "* 다중 분류에서 레이블을 다루는 두 가지 방법이 있습니다.\n",
        "    * 레이블을 범주형 인코딩(또는 원-핫 인코딩)으로 인코딩하고 `categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "    * 레이블을 정수로 인코딩하고 `sparse_categorical_crossentropy` 손실 함수를 사용합니다.\n",
        "* 많은 수의 범주를 분류할 때 중간층의 크기가 너무 작아 네트워크에 정보의 병목이 생기지 않도록 해야 합니다."
      ]
    }
  ]
}